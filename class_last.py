import torch
import argparse
import deepspeed
import os
import time
import torch.nn as nn
import numpy as np
import pandas as pd
from torch.utils.data import DataLoader,Dataset
from sklearn.metrics import classification_report,accuracy_score,hamming_loss
from transformers import AutoTokenizer, AutoModel
deepspeed.init_distributed()

def add_argument():
    parser = argparse.ArgumentParser(description='TRAIN')
    parser.add_argument('--with_cuda',
                        default=False,
                        action='store_true',
                        help='use CPU in case there\'s no GPU support')
    parser.add_argument('--path',
                        default='/home/bkcs/HDD/Thep/new-result/fine-tune/',
                        type=str)
    parser.add_argument('--type',
                        default=False)

    parser.add_argument('-e',
                        '--epochs',
                        default=10,
                        type=int,
                        help='number of total epochs (default: 30)')
    parser.add_argument('--local_rank',
                        type=int,
                        default=-1,
                        help='local rank passed from distributed launcher')

    parser.add_argument('--log-interval',
                        type=int,
                        default=2000,
                        help="output logging information at a given interval")

    parser = deepspeed.add_config_arguments(parser)
    args = parser.parse_args()
    return args



args = add_argument()
class Branch(nn.Module):
  def __init__(self, input_size, hidden_size, dropout, num_outputs):
    super(Branch, self).__init__()

    self.dense1 = nn.Linear(input_size, hidden_size)
    self.batchnorm1 = nn.BatchNorm1d(hidden_size)
    self.dropout = nn.Dropout(p=dropout)
    self.dense2 = nn.Linear(hidden_size, num_outputs)

  def forward(self, x):
    out_dense1 = self.dense1(x)
    out_batchnorm1 = self.batchnorm1(out_dense1)
    out_dropout = self.dropout(out_batchnorm1)
    out_dense2 = self.dense2(out_dropout)

    return out_dense2


class BaseModel(nn.Module):
    def __init__(self, original_model, num_classes,  is_multibranches=True):
        super(BaseModel, self).__init__()
        self.num_classes = num_classes
        self.original_model = original_model
        self.is_multibranches = is_multibranches
        branch_feature_size = 768
        if self.is_multibranches:
            self.branches = nn.ModuleList([Branch(branch_feature_size, 768, 0.1, 1) for _ in range(num_classes)])
        else:
            self.branch = Branch(branch_feature_size, 768, 0.1, num_classes)
        self.activation = nn.Sigmoid()

    def forward(self, inputs, attention_mask,is_mean):

        out =  self.original_model(input_ids=inputs.squeeze().view(-1,512), attention_mask = attention_mask.squeeze().view(-1,512))
        if is_mean:
            pooler_out = torch.mean(out.last_hidden_state,dim=1)
        else:
            pooler_out = out.last_hidden_state[:,0,:]
        if self.is_multibranches:
            output_branches = [branch(pooler_out) for branch in self.branches]
            out_branch = torch.cat(output_branches, dim=1)
        else:
            out_branch = self.branch(pooler_out)
        outputs = self.activation(out_branch)

        return outputs
    
def pad_tensor(input_tensor, target_length = 512):
    current_length = input_tensor.shape[1]
    padding_length = max(0, target_length - current_length)
    padded_tensor = torch.cat([input_tensor.squeeze(), torch.ones(padding_length)]).view(1,-1).to(torch.int64)
    return padded_tensor

class OpcodeData(Dataset):
    def __init__(self, X, tokenizer, max_len):
        self.tokenizer = tokenizer
        self.X = X
        
        self.max_len = max_len
        self.target = X.loc[:, [ 'access-control', 'arithmetic', 'reentrancy',  'unchecked-calls']]
   
    def __len__(self):
        return len(self.X)

    def __getitem__(self, index):
        values = self.X.iloc[index]['source_code']
        row = self.target.iloc[index]
        tensor_row = torch.tensor(row)
        tokens = self.tokenizer.encode(values, padding = False, return_tensors="pt", truncation=False)
        attention_mask = np.zeros(512)
        
        if(tokens.shape[1] > 512):
            tokens = tokens[:, -511:]
            slices = torch.cat([ torch.tensor([[self.tokenizer.cls_token_id]]),tokens], dim=1) 
            attention_mask[:slices.shape[1]] = 1
        else:
            attention_mask[:tokens.shape[1]] = 1
            slices = pad_tensor(tokens)
        return {
            'inputs': slices.squeeze(),
            'attention_mask':attention_mask,
            'targets': torch.tensor(tensor_row, dtype=torch.float32)
        }
max_length = 512
data_folder='/home/bkcs/HDD/Thep/'
data = pd.read_feather(data_folder+'new_data.feather')
X_train = data.loc[data['dataset'] == 'train']
X_test = data.loc[data['dataset'] == 'test']
X_val = data.loc[data['dataset'] == 'val']


token = AutoTokenizer.from_pretrained('microsoft/codebert-base')

training_set = OpcodeData(X_train, token, max_length)
validating_set = OpcodeData(X_val, token, max_length)
testing_set = OpcodeData(X_test, token, max_length)
batch_size=8
#deepspeed.init_distributed()
training_loader = DataLoader(training_set, batch_size=batch_size,shuffle=True,drop_last=True)
validating_loader = DataLoader(validating_set, batch_size=batch_size,shuffle=True,drop_last=True)
testing_loader = DataLoader(testing_set, batch_size=batch_size,shuffle=True,drop_last=True)


model =  AutoModel.from_pretrained('/home/bkcs/HDD/Thep/MLM/final_checkpoint')
for param in model.encoder.parameters():
    param.requires_grad = False

net = BaseModel(model,4)
parameters = filter(lambda p: p.requires_grad, net.parameters())

model_engine, optimizer,__, __ = deepspeed.initialize(
    args=args, model=net, model_parameters=parameters)

fp16 = model_engine.fp16_enabled()
print(f'fp16={fp16}')




criterion = nn.BCELoss()




def evaluate_steps(model,validate_loader):
    print("Evaluating...")
    model.eval()

    total_loss = 0
    total_preds = torch.tensor([])  # Initialize as empty tensor
    total_labels = torch.tensor([])


    for  i, data  in enumerate(validate_loader):
        # push the batch to gpu
        inputs, labels,attention_mask = data['inputs'].to(model.local_rank), data['targets'].to(
            model.local_rank),data['attention_mask'].to(model.local_rank)


        with torch.no_grad():
            if fp16:
                inputs = inputs.half()
            outputs = model(inputs,attention_mask,args.type)
            loss = criterion(outputs, labels)
     
            total_loss += loss.item()
           
            if i == 0:  # Initialize tensors only in the first iteration
                total_preds = torch.empty(0, *outputs.shape[1:], device=outputs.device)
                total_labels = torch.empty(0, *labels.shape[1:], device=labels.device)

            # Concatenate predictions and labels along the first dimension (batch_size)
            total_preds = torch.cat((total_preds, outputs), dim=0)
            total_labels = torch.cat((total_labels, labels), dim=0)
        


        
    TP = ((total_preds > 0.5) & (total_labels > 0.5)).sum(1).float() 
    TN = ((total_preds <= 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FP = ((total_preds > 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FN = ((total_preds <= 0.5) & (total_labels > 0.5)).sum(1).float() 

    acc = torch.mean(TP/(TP+FN+FP))

    return acc , total_loss / len(validating_loader)
            
best_val_metric = 0
path = args.path
loss_file_path = os.path.join(path, "loss.txt")
loss_file_path_val = os.path.join(path, "loss_val.txt")
start_time = time.time()


for epoch in range(10):  
    running_loss = 0.0
    model_engine.train() 
    for i, data in enumerate(training_loader):
        
        inputs, labels, attention_mask = data['inputs'].to(model_engine.local_rank), data['targets'].to(
            model_engine.local_rank),data['attention_mask'].to(model_engine.local_rank)
        if fp16:
            inputs = inputs.half()
        outputs = model_engine(inputs,attention_mask,args.type)
        loss = criterion(outputs, labels)

        model_engine.backward(loss)
        model_engine.step()
        
        # print statistics
        running_loss += loss.item()

        if i % args.log_interval == (
                args.log_interval -
                1):  # print every log_interval mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / args.log_interval))
            with open(loss_file_path, "a") as loss_file:
                loss_file.write(f"{epoch + 1},{i + 1},{running_loss / args.log_interval}\n")
            running_loss = 0.0
        
            
            

    val_metric,val_loss = evaluate_steps(model_engine, validating_loader)  # Define your evaluate_on_val_set function
    with open(loss_file_path_val, "a") as loss_file_val:
        loss_file_val.write(f"{epoch + 1},{val_loss},{val_metric}\n")

    print(val_metric)
    
    if val_metric > best_val_metric:
        best_val_metric = val_metric
        
        torch.save({
            'epoch': epoch,
            'model_state_dict': model_engine.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
        }, path + 'best_model.pth')
end_time = time.time()
total_time_seconds = end_time - start_time

print('Finished Training')


torch.save({
    'epoch': epoch,
    'model_state_dict': model_engine.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
}, path + 'finalpath.pth')


class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
sample_runtimes = []

def evaluate_steps_test(model,validate_loader):
    print("Evaluating...")
    model.eval()

    total_loss = 0
    total_preds = torch.tensor([])  # Initialize as empty tensor
    total_labels = torch.tensor([])

    
    
    for  i, data  in enumerate(validate_loader):
        # push the batch to gpu
        inputs, labels,attention_mask = data['inputs'].to(model.local_rank), data['targets'].to(
            model.local_rank),data['attention_mask'].to(model.local_rank)

        
        with torch.no_grad():
            if fp16:
                inputs = inputs.half()
            start_time_k = time.time()
            outputs = model(inputs,attention_mask,args.type)
            end_time_k = time.time()
            if i == 0:  # Initialize tensors only in the first iteration
                total_preds = torch.empty(0, *outputs.shape[1:], device=outputs.device)
                total_labels = torch.empty(0, *labels.shape[1:], device=labels.device)
            total_preds = torch.cat((total_preds, (outputs>0.5)), dim=0)
            total_labels = torch.cat((total_labels, labels), dim=0)
        sample_runtimes.append(end_time_k - start_time_k)
    average_runtime = np.mean(sample_runtimes)/batch_size

    TP = ((total_preds > 0.5) & (total_labels > 0.5)).sum(1).float() 
    TN = ((total_preds <= 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FP = ((total_preds > 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FN = ((total_preds <= 0.5) & (total_labels > 0.5)).sum(1).float() 

    precision = torch.mean(TP / (TP + FP + 1e-12))
    recall = torch.mean(TP / (TP + FN + 1e-12))
    f2 =  precision * recall / (precision + recall + 1e-12)
    labels = total_labels.cpu().numpy()
    preds = total_preds.cpu().numpy()

    label_names = [ 'access-control', 'arithmetic',  'reentrancy',  'unchecked-calls']
    out = classification_report( labels,preds, output_dict=True,target_names=label_names)
    total_support = out['samples avg']['support']
    acc = accuracy_score(labels,preds)
    hm = hamming_loss(labels,preds)

    acc_s =  torch.mean(TP/(TP+FN+FP)).cpu().numpy()

    out['Exact Match Ratio'] = {'precision': acc, 'recall': acc, 'f1-score': acc, 'support': total_support}
    out['Hamming Loss'] = {'precision': hm, 'recall': hm, 'f1-score': hm, 'support': total_support}
    out['Accuracy'] = {'precision': acc_s, 'recall': acc_s, 'f1-score': acc_s, 'support': total_support}
    out['TimeTraing'] = {'precision': total_time_seconds, 'recall': total_time_seconds, 'f1-score': total_time_seconds, 'support': total_time_seconds}
    out['Timepersample'] = {'precision': average_runtime, 'recall': average_runtime, 'f1-score': average_runtime, 'support': average_runtime}
    
    out_df = pd.DataFrame(out).transpose()
    print(out_df)

    out_df.to_csv(path+"result.csv")
    
    return out_df
checkpoint = torch.load( path + 'best_model.pth')
model_engine.load_state_dict(checkpoint['model_state_dict'])
with torch.no_grad():
    evaluate_steps_test(model_engine, testing_loader)

