import torch
import argparse
import deepspeed
import os
import time
import torch.nn as nn
import numpy as np
from tqdm import tqdm 

import pandas as pd
from torch.utils.data import DataLoader,Dataset
from sklearn.metrics import classification_report,accuracy_score,hamming_loss
from transformers import AutoTokenizer, AutoModel


def add_argument():
    parser = argparse.ArgumentParser(description='TRAIN')
    parser.add_argument('--with_cuda',
                        default=False,
                        action='store_true',
                        help='use CPU in case there\'s no GPU support')
    parser.add_argument('--path',
                        default='Thep/new-result',
                        type=str)
    parser.add_argument('--type',
                        default=True)

    parser.add_argument('-e',
                        '--epochs',
                        default=10,
                        type=int,
                        help='number of total epochs (default: 30)')
    parser.add_argument('--local_rank',
                        type=int,
                        default=-1,
                        help='local rank passed from distributed launcher')

    parser.add_argument('--log-interval',
                        type=int,
                        default=2000,
                        help="output logging information at a given interval")
    parser.add_argument('--block',
                        type=int,
                        default=2,
                        help="block")
    parser = deepspeed.add_config_arguments(parser)
    args = parser.parse_args()
    return args

def pad_tensor(input_tensor, target_length=512):
    current_length = input_tensor.shape[1]
    padding_length = max(0, target_length - current_length)
    padded_tensor = torch.cat([input_tensor.squeeze(), torch.ones(padding_length)]).view(1,-1).to(torch.int64)
    return padded_tensor

def pad_tensor_pad(target_length=512):
    return torch.ones(target_length).to(torch.int64).view(-1,512)

def process_long_text_sequences_from_dataframe( text, tokenizer,block, max_length=512):
    processed_tensors = []
    attention_masks = []
    tokens = tokenizer.encode(text, padding = False, return_tensors="pt", truncation=False)
    k = 0

    if tokens.size(1)-2 >= (max_length-2)*block:
        i = 0
        while(True):
            k += 1
            if i == 0:
                slice = tokens[:,-max_length+1:]
                slices = torch.cat([ torch.tensor([[tokenizer.cls_token_id]]),slice], dim=1) 
            elif (i + max_length - 2) >= tokens.size(1):
                slice = tokens[:,0: tokens.size(1)-i]
                slices = torch.cat([slice, torch.tensor([[tokenizer.sep_token_id]])], dim=1)
                attention_mask = np.zeros(512)
                attention_mask[:slices.shape[1]] = 1
                attention_masks.append(attention_mask)
                processed_tensors.append(pad_tensor(slices))
                break
            else:
                slice = tokens[:,-(i + max_length -2)  : -i]
                slices = torch.cat([torch.tensor([[tokenizer.cls_token_id]]), slice, torch.tensor([[tokenizer.sep_token_id]])], dim=1)

            i +=  max_length - 2 
            attention_mask = np.zeros(512)
            attention_mask[:slices.shape[1]] = 1
            attention_masks.append(attention_mask)
            processed_tensors.append(slices)
            if k == block:
                break
        processed_tensors.reverse()
        attention_masks.reverse()
    else:
        i = 0
        if tokens.size(1) < max_length:
            attention_mask = np.zeros(512)
            attention_mask[:tokens.shape[1]] = 1
            attention_masks.append(attention_mask)
            processed_tensors.append(pad_tensor(tokens))
            k += 1 
        else:
            while(True):
                k += 1
                if i == 0:
                    slice = tokens[:,0: max_length - 1]
                    slices = torch.cat([slice, torch.tensor([[tokenizer.sep_token_id]])], dim=1)
                elif (i + max_length - 2) >= tokens.size(1):
                    slice = tokens[:,i: tokens.size(1)]
                    slices = torch.cat([ torch.tensor([[tokenizer.cls_token_id]]),slice], dim=1) 
                    attention_mask = np.zeros(512)
                    attention_mask[:slices.shape[1]] = 1
                    attention_masks.append(attention_mask)
                    processed_tensors.append(pad_tensor(slices))
                    break
                else:
                    slice = tokens[:,i+1: i + max_length -1]
                    slices = torch.cat([torch.tensor([[tokenizer.cls_token_id]]), slice, torch.tensor([[tokenizer.sep_token_id]])], dim=1)

                i +=  max_length - 2 
                attention_mask = np.zeros(512)
                attention_mask[:slices.shape[1]] = 1
                attention_masks.append(attention_mask)
                processed_tensors.append(pad_tensor(slices))
                if k == block:
                    break
    return torch.cat(processed_tensors, dim=0) , np.vstack(attention_masks) , k

class OpcodeData(Dataset):
    def __init__(self, X, tokenizer, max_len, max_block ):
        self.tokenizer = tokenizer
        self.X = X
        self.max_block = max_block
        self.pad = pad_tensor_pad()
        self.max_len = max_len
        self.target = X.loc[:,  [ 'access-control', 'arithmetic', 'reentrancy',  'unchecked-calls']]
   
    def __len__(self):
        return len(self.X)

    def __getitem__(self, index):
        values = self.X.iloc[index]['source_code']
        row = self.target.iloc[index]
        tensor_row = torch.tensor(row)
        token, attention_mask,k = process_long_text_sequences_from_dataframe(values,self.tokenizer,self.max_block)
        if(k < self.max_block):
            for _ in range(self.max_block - k ):
                token =  torch.cat([token,self.pad], dim=0)
                attention_mask = np.vstack([attention_mask,np.zeros(512)]) 
                
                
        return {
            'inputs': token.view(-1,512),
            'attention_mask':attention_mask,
            'targets': torch.tensor(tensor_row, dtype=torch.float32)
        }
args = add_argument()

class Branch(nn.Module):
  def __init__(self, input_size, hidden_size, dropout, num_outputs):
    super(Branch, self).__init__()

    self.dense1 = nn.Linear(input_size, hidden_size)
    self.batchnorm1 = nn.BatchNorm1d(hidden_size)
    self.activation = nn.ReLU
    self.dropout = nn.Dropout(p=dropout)
    self.dense2 = nn.Linear(hidden_size, num_outputs)

  def forward(self, x):
    out_dense1 = self.dense1(x)
    out_batchnorm1 = self.batchnorm1(out_dense1)
    out_dropout = self.dropout(out_batchnorm1)
    out_dense2 = self.dense2(out_dropout)

    return out_dense2


class BaseModel(nn.Module):
    def __init__(self, original_model, num_classes,block,  is_multibranches=False):
        super(BaseModel, self).__init__()
        self.num_classes = num_classes
        self.original_model = original_model
        self.is_multibranches = is_multibranches
        branch_feature_size = 768*block                                                         
        self.block = block
        if self.is_multibranches:
            self.branches = nn.ModuleList([Branch(branch_feature_size, 768, 0.1, 1) for _ in range(num_classes)])
        else:
            self.branch = Branch(branch_feature_size, 768, 0.1, num_classes)
        self.activation = nn.Sigmoid()

    def forward(self, inputs, attention_mask,is_mean):
        for i in range(self.block): 
            out = self.original_model(input_ids=inputs[:, i, :].squeeze().view(-1,512),attention_mask=attention_mask[:, i, :].squeeze().view(-1,512))
            if is_mean:
                mean = torch.mean(out.last_hidden_state,dim=1)
            else:
                mean = out.last_hidden_state[:,0,:]
            if i == 0:
                pooler_out = mean                                                                                                                                                           
            else:
                pooler_out = torch.cat([pooler_out, mean], dim=1)

        if self.is_multibranches:
            output_branches = [branch(pooler_out) for branch in self.branches]
            out_branch = torch.cat(output_branches, dim=1)
        else:
            out_branch = self.branch(pooler_out)
        
        outputs = self.activation(out_branch)
        return outputs.float()
    
block = args.block    
path = args.path+str(block)+'/'
model=  AutoModel.from_pretrained('microsoft/codebert-base')
for param in model.encoder.parameters():
    param.requires_grad = False

net = BaseModel(model,4,block)


parameters = filter(lambda p: p.requires_grad, net.parameters())
model_engine, optimizer,__, __ = deepspeed.initialize(
    args=args, model=net, model_parameters=parameters)

fp16 = model_engine.fp16_enabled()

print(f'fp16={fp16}')

data_folder='/home/bkcs/HDD/Thep/'

max_length = 512

data_folder='/home/bkcs/HDD/Thep/'
data = pd.read_feather(data_folder+'new_data.feather')
X_train = data.loc[data['dataset'] == 'train']
X_test = data.loc[data['dataset'] == 'test']
X_val = data.loc[data['dataset'] == 'val']


token = AutoTokenizer.from_pretrained('microsoft/codebert-base')

training_set = OpcodeData(X_train, token, max_length,block )
validating_set = OpcodeData(X_val, token, max_length,block)
testing_set = OpcodeData(X_test, token, max_length,block)
batch_size=2
training_loader = DataLoader(training_set, batch_size=batch_size,shuffle=True,drop_last=True)
validating_loader = DataLoader(validating_set, batch_size=batch_size,shuffle=True,drop_last=True)
testing_loader = DataLoader(testing_set, batch_size=batch_size,shuffle=True,drop_last=True)

criterion = nn.BCELoss()




def evaluate_steps(model,validate_loader):
    print("Evaluating...")
    model.eval()

    total_loss = 0
    total_preds = torch.tensor([])  # Initialize as empty tensor
    total_labels = torch.tensor([])


    for  i, data  in enumerate(validate_loader):
        # push the batch to gpu
        inputs, labels,attention_mask = data['inputs'].to(model.local_rank), data['targets'].to(
            model.local_rank),data['attention_mask'].to(model.local_rank)

        with torch.no_grad():
            if fp16:
                inputs = inputs.half()
            outputs = model(inputs,attention_mask,args.type)
            loss = criterion(outputs, labels)
     
            total_loss += loss.item()
           
            if i == 0:  # Initialize tensors only in the first iteration
                total_preds = torch.empty(0, *outputs.shape[1:], device=outputs.device)
                total_labels = torch.empty(0, *labels.shape[1:], device=labels.device)

            # Concatenate predictions and labels along the first dimension (batch_size)
            total_preds = torch.cat((total_preds, outputs), dim=0)
            total_labels = torch.cat((total_labels, labels), dim=0)


        
    TP = ((total_preds > 0.5) & (total_labels > 0.5)).sum(1).float() 
    TN = ((total_preds <= 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FP = ((total_preds > 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FN = ((total_preds <= 0.5) & (total_labels > 0.5)).sum(1).float() 

    acc = torch.mean(TP/(TP+FN+FP))

    return acc , total_loss / len(validating_loader)
            
best_val_metric = 0

loss_file_path = os.path.join(path, "loss.txt")
loss_file_path_val = os.path.join(path, "loss_val.txt")
start_time = time.time()


for epoch in range(10):  
    bar = tqdm(training_loader,total=len(training_loader))
    running_loss = 0.0
    model_engine.train() 
    for i, data in enumerate(bar):
        
        
        inputs, labels,attention_mask = data['inputs'].to(model_engine.local_rank), data['targets'].to(
            model_engine.local_rank),data['attention_mask'].to(model_engine.local_rank)
        if fp16:
            inputs = inputs.half()
        outputs = model_engine(inputs,attention_mask,args.type)
        outputs.to
        loss = criterion(outputs, labels)

        model_engine.backward(loss)
        model_engine.step()
        bar.set_description("idx {} loss {}".format(i,round(np.mean(loss.item()),3)))
        running_loss += loss.item()
        if i % args.log_interval == (
                args.log_interval -
                1):  # print every log_interval mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / args.log_interval))
            with open(loss_file_path, "a") as loss_file:
                loss_file.write(f"{epoch + 1},{i + 1},{running_loss / args.log_interval}\n")
            running_loss = 0.0
            
            

    val_metric,val_loss = evaluate_steps(model_engine, validating_loader)  # Define your evaluate_on_val_set function
    with open(loss_file_path_val, "a") as loss_file_val:
        loss_file_val.write(f"{epoch + 1},{val_loss},{val_metric}\n")

    print(val_metric)
    
    if val_metric > best_val_metric:
        best_val_metric = val_metric
        
        torch.save({
            'epoch': epoch,
            'model_state_dict': model_engine.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
        }, path + 'best_model.pth')
end_time = time.time()
total_time_seconds = end_time - start_time

print('Finished Training')


torch.save({
    'epoch': epoch,
    'model_state_dict': model_engine.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
}, path + 'finalpath.pth')


class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
sample_runtimes = []

def evaluate_steps_test(model,validate_loader):
    print("Evaluating...")
    model.eval()
    total_loss = 0
    total_preds = torch.tensor([])  # Initialize as empty tensor
    total_labels = torch.tensor([])

    
    
    for  i, data  in enumerate(validate_loader):
        # push the batch to gpu
        inputs, labels,attention_mask = data['inputs'].to(model.local_rank), data['targets'].to(
            model.local_rank),data['attention_mask'].to(model.local_rank)

        with torch.no_grad():
            if fp16:
                inputs = inputs.half()
            start_time_k = time.time()
            outputs = model(inputs,attention_mask,args.type)
            end_time_k = time.time()
            if i == 0:  # Initialize tensors only in the first iteration
                total_preds = torch.empty(0, *outputs.shape[1:], device=outputs.device)
                total_labels = torch.empty(0, *labels.shape[1:], device=labels.device)
            total_preds = torch.cat((total_preds, (outputs>0.5)), dim=0)
            total_labels = torch.cat((total_labels, labels), dim=0)
        sample_runtimes.append(end_time_k - start_time_k)
    average_runtime = np.mean(sample_runtimes)/batch_size

    TP = ((total_preds > 0.5) & (total_labels > 0.5)).sum(1).float() 
    TN = ((total_preds <= 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FP = ((total_preds > 0.5) & (total_labels <= 0.5)).sum(1).float() 
    FN = ((total_preds <= 0.5) & (total_labels > 0.5)).sum(1).float() 

    precision = torch.mean(TP / (TP + FP + 1e-12))
    recall = torch.mean(TP / (TP + FN + 1e-12))
    f2 =  precision * recall / (precision + recall + 1e-12)
    labels = total_labels.cpu().numpy()
    preds = total_preds.cpu().numpy()

    label_names =  [ 'access-control', 'arithmetic', 'reentrancy',  'unchecked-calls']
    out = classification_report( labels,preds, output_dict=True,target_names=label_names)
    total_support = out['samples avg']['support']
    acc = accuracy_score(labels,preds)
    hm = hamming_loss(labels,preds)

    acc_s =  torch.mean(TP/(TP+FN+FP)).cpu().numpy()

    out['Exact Match Ratio'] = {'precision': acc, 'recall': acc, 'f1-score': acc, 'support': total_support}
    out['Hamming Loss'] = {'precision': hm, 'recall': hm, 'f1-score': hm, 'support': total_support}
    out['Accuracy'] = {'precision': acc_s, 'recall': acc_s, 'f1-score': acc_s, 'support': total_support}
    out['TimeTraing'] = {'precision': total_time_seconds, 'recall': total_time_seconds, 'f1-score': total_time_seconds, 'support': total_time_seconds}
    out['Timepersample'] = {'precision': average_runtime, 'recall': average_runtime, 'f1-score': average_runtime, 'support': average_runtime}
    
    out_df = pd.DataFrame(out).transpose()
    print(out_df)

    out_df.to_csv(path+"result.csv")
    
    return out_df
checkpoint = torch.load( path + 'best_model.pth')
model_engine.load_state_dict(checkpoint['model_state_dict'])
with torch.no_grad():
    evaluate_steps_test(model_engine, testing_loader)


